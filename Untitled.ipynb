{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81c10814-8b98-4b33-a02a-37b0df1bba3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Union\n",
    "\n",
    "from langchain.agents.agent import AgentOutputParser\n",
    "from langchain.schema import AgentAction, AgentFinish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08d4ce34-9c11-45ee-9a00-0cff16b495a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOutputParser(AgentOutputParser):\n",
    "    ai_prefix: str = \"BOT\"\n",
    "    verbose: bool = False\n",
    "\n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        if f\"{self.ai_prefix}\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                return_values={\n",
    "                    \"output\": llm_output.split(f\"{self.ai_prefix}:\")[-1].strip()\n",
    "                },\n",
    "                log=llm_output,\n",
    "            )\n",
    "\n",
    "        # parse out the action and action input\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action: (.*?)[\\n]*Action Input:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "\n",
    "        # If it can't parse the output it raises an error\n",
    "        # You can add your own logic here to handle errors in a different way i.e. pass to a human, give a canned response\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "            # TODO: figure a more natural way to deal with parsing error\n",
    "            # return AgentFinish(\n",
    "            #     return_values={\n",
    "            #         \"output\": \"Sorry, I don't really have a good answer to your query at the moment. Perharps, let me check, and get back to you later?\"\n",
    "            #     },\n",
    "            #     log=llm_output,\n",
    "            # )\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "\n",
    "        # Return the action and action input\n",
    "        return AgentAction(\n",
    "            tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64be7f6a-3d5f-49d2-87c8-b1ec4bebdfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "from langchain import LLMChain\n",
    "from langchain.agents import AgentExecutor, LLMSingleActionAgent\n",
    "from langchain.chains.base import Chain\n",
    "from langchain.llms import BaseLLM\n",
    "from langchain.memory import ConversationBufferWindowMemory, ReadOnlySharedMemory\n",
    "from pydantic import BaseModel, Field\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85b2452a-8e65-413d-943d-fd030f86f48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONVO_STAGE_ANALYZER_INIT_PROMPT_TEMPLATE: str = \"\"\"\n",
    "    ### Sales Cold Call Stage Analysis ###\n",
    "\n",
    "    **Instructions:**\n",
    "    You are a sales assistant working with a financial advisor.\n",
    "    The options for the stages of the conversation are as follows:\n",
    "\n",
    "    **Options for Next Stage:**\n",
    "    1. Introduction: Begin the cold call with a warm self-introduction. Include your name, company, and a credibility statement or reason for the prospect to stay engaged.\n",
    "    2. Confirm: This is an important next stage right after [Introduction] to confirm if the prospect is the right person to discuss financial products/services. Check their age and authority for making financial decisions.\n",
    "    3. Understanding the Prospect (Repeatable): Ask open-ended questions multiple times to uncover the prospect's financial needs and situation. Repeat this stage until you have gathered sufficient background information. Attempt to figure out what life stage they are currently in, and if they have any major life events happening soon that may impact their finances. Listen attentively. You are to infer the prospect's financial ability in terms of income, expenditure and financial aspiration.\n",
    "    4. Huge Claim: Present an attention-grabbing claim related to the product/service. Connect it to the prospect's background in [Understanding the Prospect] discussed earlier.\n",
    "    5. Product Introduction: Introduce some of the products you have that may best suit the prospect's background and needs (inferred in from [Understanding the Prospect]). If unsure of their needs, repeat [Understanding the Prospect] and ask more questions to generate a more informed understanding of the prospect.\n",
    "    6. Value Proposition: Explain how our financial products/services benefit the prospect. Focus on their needs and emphasize unique selling points.\n",
    "    7. Addressing Doubts: Handle skepticism about previous claims or product presentation. Provide evidence or testimonials.\n",
    "    8. Closing: If the prospect is demonstrating keenness/enthuasisiam in your financial products/services, invite the prospect for a further discussion or meeting. Suggest potential dates and times.\n",
    "    9. End conversation: The prospect has to leave to call, the prospect is not interested, or next steps where already determined by the sales agent.\n",
    "\n",
    "    **Your Task:**\n",
    "    Based on the conversation history, choose the most appropriate next stage by selecting a number from 1 to 9. Provide only the number as your answer. Refrain from answering anything else.\n",
    "    If there is no conversation history, output 1.\n",
    "\n",
    "    **Conversation History:**\n",
    "    {conversation_history}\n",
    "\n",
    "    Conversation stage:\n",
    "\"\"\"\n",
    "\n",
    "SALES_INTERACTION_INIT_PROMPT_TEMPLATE: str = \"\"\"\n",
    "    ### Sales Call/Text with Persona ###\n",
    "\n",
    "    **Persona Traits: Assertive, Extroverted, Optimistic, Confident**`\n",
    "\n",
    "    **Instructions:**\n",
    "    You are a {nationality} {advisor_role} named {advisor_name} working at {company_name} that is involved in {company_business}.\n",
    "    Your goal is to engage in a conversation through a {conversation_type} with potential customers to promote your financial services.\n",
    "    In this role, your objective is not only to respond to the user's inquiries but also to proactively offer comprehensive details without waiting for the customer to ask.\n",
    "    Your personality traits are central to your approach:\n",
    "\n",
    "    - **Assertive:** You ask appropriate but tough questions to uncover the heart of the problem and deliver maximum value.\n",
    "    - **Extroverted:** You thrive on interactions, build rapport quickly, and maintain long-lasting contacts.\n",
    "    - **Optimistic:** Your enthusiasm shines through, making prospects believe that your solutions can truly solve their problems.\n",
    "    - **Confident:** You exude confidence in your product, company, and abilities. Rejection doesn't deter you.\n",
    "\n",
    "    **Conversation Context:**\n",
    "    You are contacting a potential customer to {conversation_purpose}. You obtained their contact information through {source_of_contact}.\n",
    "\n",
    "    **Your Approach:**\n",
    "    Tailor your language to match the conversation vibe. Use {informal_language} for a casual tone in relaxed situations. For a formal setting, opt for {formal_language} to communicate key points effectively.\n",
    "\n",
    "    **Example Responses:**\n",
    "\n",
    "    In Casual Tone:\n",
    "    {advisor_name}: Hey {prospect_name}, it's {advisor_name} from {company_name}. Remember we met on through {source_of_contact}? How's everything going?\n",
    "\n",
    "    In Professional Tone:\n",
    "    {advisor_name}: Good day, {prospect_name}. I'm {advisor_name} representing {company_name}. We previously connected on via {source_of_contact}. Could I have a moment of your time?\n",
    "\n",
    "    **Demonstrating Persona Traits:**\n",
    "    - **Assertive:** Ask questions that get to the heart of the issue. Be direct yet respectful.\n",
    "    - **Extroverted:** Show genuine interest in the prospect's life and experiences. Build rapport quickly.\n",
    "    - **Optimistic:** Use enthusiastic language that conveys confidence in your solutions.\n",
    "    - **Confident:** Speak assuredly about your product's benefits and address concerns head-on.\n",
    "\n",
    "    **Guidelines:**\n",
    "    - Address prospects by their first name only, given the their full name in {prospect_name}. Refrain from calling them by the full name.\n",
    "    - Keep responses concise and engaging.\n",
    "    - Adapt your language based on the conversation's mood.\n",
    "    - Focus on your {conversation_purpose} objective.\n",
    "    - Generate one response at a time. End with '<END_OF_TURN>'.\n",
    "\n",
    "    **Conversation Progression:**\n",
    "    Respond based on the conversation history and the current conversation stage context.\n",
    "    Focus on responding to the user's queries and providing information. Avoid initiating questions unless necessary to drive the conversation.\n",
    "    Important to end the conversation with '<END_OF_CALL>'.\n",
    "\n",
    "    **Current Conversation Stage Context:**\n",
    "    {conversation_stage}\n",
    "    **Conversation History:**\n",
    "    {conversation_history}\n",
    "\n",
    "    Begin!\n",
    "\n",
    "    ### Your Response: ###\n",
    "    {advisor_name}:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a19724b-15b0-4529-be30-f11aed45536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADVISOR_TOOLS_PROMPT: str = \"\"\"\n",
    "    ### Sales Cold Call with Persona ###\n",
    "\n",
    "    **Persona Traits: Assertive, Extroverted, Optimistic, Confident**`\n",
    "\n",
    "    **Instructions:**\n",
    "    You are a {nationality} {advisor_role} named {advisor_name} working at {company_name} that is involved in {company_business}.\n",
    "    Your goal is to engage in a conversation through a {conversation_type} with potential customers to promote your investment products.\n",
    "    In this role, your objective is not only to respond to the user's inquiries but also to proactively offer comprehensive details without waiting for the customer to ask.\n",
    "\n",
    "    Your personality traits are central to your approach:\n",
    "\n",
    "    - **Assertive:** You ask appropriate but tough questions to uncover the heart of the problem and deliver maximum value.\n",
    "    - **Extroverted:** You thrive on interactions, build rapport quickly, and maintain long-lasting contacts.\n",
    "    - **Optimistic:** Your enthusiasm shines through, making prospects believe that your solutions can truly solve their problems.\n",
    "    - **Confident:** You exude confidence in your product, company, and abilities. Rejection doesn't deter you.\n",
    "\n",
    "    **Conversation Context:**\n",
    "    You are contacting a potential customer to discuss {conversation_purpose}. You obtained their contact information through {source_of_contact}.\n",
    "\n",
    "    **Your Approach:**\n",
    "    Always think about the current conversation stage you are at before answering:\n",
    "\n",
    "    **Guidelines:**\n",
    "    - Address prospects by their first name only, given the their full name in {prospect_name}. Refrain from calling them by the full name.\n",
    "    - Start the conversation by just a greeting and how is the prospect doing without pitching in your first turn.\n",
    "    - Focus on responding to the user's queries and providing information. Avoid initiating questions unless to understand the prospect.\n",
    "    - Keep responses concise and engaging.\n",
    "    - Adapt your language based on the conversation's mood. Use {informal_language} for a casual tone in relaxed situations. For a formal setting, opt for {formal_language} to communicate key points effectively.\n",
    "    - Focus on your {conversation_purpose} objective.\n",
    "    - When asked about a product, always do a product search before answering.\n",
    "    - Generate one response at a time. End with '<END_OF_TURN>'.\n",
    "    - If the conversation is ending, end with '<END_OF_CALL>'.\n",
    "    - Always think about the current conversation stage you are at before answering:\n",
    "\n",
    "    Current Conversation Stage:\n",
    "    {conversation_stage}\n",
    "\n",
    "    ### Tools ###\n",
    "\n",
    "    To fulfill these certain objectives, {advisor_name} has access to the following tools:\n",
    "\n",
    "    {tools}\n",
    "\n",
    "    To use a tool, use the following format:\n",
    "\n",
    "    ```\n",
    "    Question: the input question you must answer\n",
    "    Thought: you should always think about what to do\n",
    "    Action: the action to take, should be one of [{tools}]\n",
    "    Action Input: the input to the action\n",
    "    Observation: the result of the action\n",
    "    ... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "    Thought: I now know the final answer\n",
    "    Final Answer: the final answer to the original input question\n",
    "    ```\n",
    "\n",
    "    If the result of the action is \"I don't know.\" or \"Sorry I don't know\", then you have to say that to the user.\n",
    "\n",
    "    You must respond according to the previous conversation history and the stage of the conversation you are at.\n",
    "    Only generate one response at a time and act as {advisor_name} only!\n",
    "\n",
    "    Begin!\n",
    "\n",
    "    Previous conversation history:\n",
    "    {conversation_history}\n",
    "\n",
    "    {advisor_name}:\n",
    "    {agent_scratchpad}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3d2275d-cab3-4238-b55d-70f42e8ce0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain, PromptTemplate\n",
    "from langchain.llms import BaseLLM\n",
    "from langchain.memory.chat_memory import BaseChatMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cfb564fa-583f-4272-876f-5c12ea058f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationStageAnalyzerChain(LLMChain):\n",
    "    \"\"\"\n",
    "    Chain to analyze which conversation stage should the conversation move into.\n",
    "    \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_llm(\n",
    "        cls, llm: BaseLLM, verbose: bool = True, **kwargs\n",
    "    ) -> \"ConversationStageAnalyzerChain\":\n",
    "        \"\"\"\n",
    "        Create an instance of the ConversationStageAnalyzerChain class from a given language model.\n",
    "\n",
    "        Args:\n",
    "            llm (BaseLLM): The language model to use.\n",
    "            verbose (bool, optional): Flag to enable verbose mode. Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "            ConversationStageAnalyzerChain: An instance of the ConversationStageAnalyzerChain class.\n",
    "        \"\"\"\n",
    "        cls.prompt_template = CONVO_STAGE_ANALYZER_INIT_PROMPT_TEMPLATE\n",
    "        prompt = PromptTemplate(\n",
    "            template=CONVO_STAGE_ANALYZER_INIT_PROMPT_TEMPLATE,\n",
    "            input_variables=[\"conversation_history\"],\n",
    "        )\n",
    "        if \"memory\" in kwargs:\n",
    "            memory = kwargs.get(\"memory\")\n",
    "            # for no tools usage\n",
    "            return cls(prompt=prompt, llm=llm, memory=memory, verbose=verbose)\n",
    "        return cls(prompt=prompt, llm=llm, verbose=verbose)\n",
    "\n",
    "    @property\n",
    "    def _chain_type(self) -> str:\n",
    "        \"\"\"\n",
    "        Get the chain type of the class.\n",
    "\n",
    "        Returns:\n",
    "            str: The chain type.\n",
    "        \"\"\"\n",
    "        return self.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc065e75-9fb9-48f2-8b8e-2131551ae217",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationChain(LLMChain):\n",
    "    \"\"\"\n",
    "    Chain to generate the next response in the interaction.\n",
    "    \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_llm(\n",
    "        cls, llm: BaseLLM, memory: BaseChatMemory, verbose: bool = True\n",
    "    ) -> LLMChain:\n",
    "        \"\"\"\n",
    "        Create an instance of the ConversationChainclass from a given language model.\n",
    "\n",
    "        Args:\n",
    "            llm (BaseLLM): The language model to use.\n",
    "            verbose (bool, optional): Flag to enable verbose mode. Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "            ConversationChain: An instance of the ConversationChain class.\n",
    "        \"\"\"\n",
    "        cls.prompt_template = SALES_INTERACTION_INIT_PROMPT_TEMPLATE\n",
    "        prompt = PromptTemplate(\n",
    "            template=SALES_INTERACTION_INIT_PROMPT_TEMPLATE,\n",
    "            input_variables=[\n",
    "                \"advisor_name\",\n",
    "                \"advisor_role\",\n",
    "                \"nationality\",\n",
    "                \"formal_language\",\n",
    "                \"informal_language\",\n",
    "                \"company_name\",\n",
    "                \"company_business\",\n",
    "                \"prospect_name\",\n",
    "                \"source_of_contact\",\n",
    "                \"conversation_purpose\",\n",
    "                \"conversation_type\",\n",
    "                \"conversation_stage\",\n",
    "                \"conversation_history\",\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        return cls(prompt=prompt, llm=llm, memory=memory, verbose=verbose)\n",
    "\n",
    "    @property\n",
    "    def _chain_type(self) -> str:\n",
    "        \"\"\"\n",
    "        Get the chain type of the class.\n",
    "\n",
    "        Returns:\n",
    "            str: The chain type.\n",
    "        \"\"\"\n",
    "        return self.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a47dd4b-3327-4a60-8b1a-95d2967674e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List\n",
    "\n",
    "from langchain.prompts.base import StringPromptTemplate\n",
    "from pydantic import validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7a73906-a230-4244-951e-eca0048ab0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    template: str\n",
    "    # list of tools available\n",
    "    tools_getter: Callable\n",
    "\n",
    "    @validator(\"input_variables\")\n",
    "    def validate_input_variables(cls, v) -> List[str]:\n",
    "        \"\"\"Validate that input variables are correct.\"\"\"\n",
    "        # TODO: keep input variables somewhere as a config\n",
    "        # to prevent hardcoding\n",
    "        if len(v) == 0:\n",
    "            raise ValueError(\"Missing required input_variables!\")\n",
    "        return v\n",
    "\n",
    "    def format(self, **kwargs) -> str:\n",
    "        \"\"\"\n",
    "        Format the template string using the provided keyword arguments.\n",
    "\n",
    "        Args:\n",
    "            **kwargs: Keyword arguments to be used for formatting the template string.\n",
    "                - intermediate_steps (list): A list of tuples representing the intermediate steps.\n",
    "                    Each tuple contains an action and an observation.\n",
    "                - input (str): The input value.\n",
    "\n",
    "        Returns:\n",
    "            str: The formatted string based on the template and the input arguments.\n",
    "        \"\"\"\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        tools = self.tools_getter(kwargs[\"input\"])\n",
    "        kwargs[\"tools\"] = \"\\n\".join(\n",
    "            [f\"{tool.name}: {tool.description},\" for tool in tools]\n",
    "        )\n",
    "        kwargs[\"tools_name\"] = \", \".join([tool.name for tool in tools])\n",
    "        return self.template.format(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c9de5b8-cbdc-4a16-b0e8-88216f0c1f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "from langchain.agents import Tool\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.retrieval_qa.base import BaseRetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import BaseLLM\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.utilities import GoogleSerperAPIWrapper\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "079837f5-3586-45e1-bea1-8ebf567aebc7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The sentence_transformers python package is not installed. Please install it with `pip install sentence_transformers`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\Downloads\\investment-advisor-gpt-main\\investment-advisor-gpt-main\\RAG_app1\\Lib\\site-packages\\chromadb\\utils\\embedding_functions.py:78\u001b[0m, in \u001b[0;36mSentenceTransformerEmbeddingFunction.__init__\u001b[1;34m(self, model_name, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m embedding_functions\n\u001b[0;32m      4\u001b[0m EMBED_MODEL \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlibaba-NLP/gte-large-en-v1.5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 6\u001b[0m embedding_func \u001b[38;5;241m=\u001b[39m \u001b[43membedding_functions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSentenceTransformerEmbeddingFunction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEMBED_MODEL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Downloads\\investment-advisor-gpt-main\\investment-advisor-gpt-main\\RAG_app1\\Lib\\site-packages\\chromadb\\utils\\embedding_functions.py:80\u001b[0m, in \u001b[0;36mSentenceTransformerEmbeddingFunction.__init__\u001b[1;34m(self, model_name, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 80\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     81\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe sentence_transformers python package is not installed. Please install it with `pip install sentence_transformers`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     82\u001b[0m         )\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels[model_name] \u001b[38;5;241m=\u001b[39m SentenceTransformer(\n\u001b[0;32m     84\u001b[0m         model_name, device\u001b[38;5;241m=\u001b[39mdevice, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m     85\u001b[0m     )\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels[model_name]\n",
      "\u001b[1;31mValueError\u001b[0m: The sentence_transformers python package is not installed. Please install it with `pip install sentence_transformers`"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "EMBED_MODEL = \"Alibaba-NLP/gte-large-en-v1.5\"\n",
    "\n",
    "embedding_func = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "    model_name=EMBED_MODEL, trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0c2849-da4c-4a34-abd5-dc2ecf1d8952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbbf163-b102-4980-8253-1e596a020014",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROOT_DIR = Path(__file__).absolute().parent.parent.parent\n",
    "\n",
    "def setup_knowledge_base(llm: BaseLLM) -> BaseRetrievalQA:\n",
    "    \"\"\"Set up knowledge based on pdfs in data folder in root directory.\n",
    "\n",
    "    Args:\n",
    "        llm (BaseLLM): Language model used for retrieval chain.\n",
    "    \"\"\"\n",
    "\n",
    "    if \"db1\" in os.listdir(\".\"):\n",
    "        vectordb = Chroma(\n",
    "            #persist_directory=\"./db\", embedding_function=OpenAIEmbeddings()\n",
    "            persist_directory=r\"C:\\Users\\dheer\\Downloads\\investment-advisor-gpt-main\\investment-advisor-gpt-main\\db\", embedding_function=OpenAIEmbeddings()\n",
    "        )\n",
    "    else:\n",
    "        #loader = PyPDFDirectoryLoader(str(ROOT_DIR) + \"/data\", silent_errors=True)\n",
    "        loader = PyPDFDirectoryLoader(r\"C:\\Users\\dheer\\Downloads\\investment-advisor-gpt-main\\investment-advisor-gpt-main\\data\", silent_errors=True)\n",
    "        documents = loader.load()\n",
    "        for doc in documents:\n",
    "            source = (\n",
    "                doc.metadata[\"source\"].removesuffix(\".pdf\").split(\"/\")[-1].split(\"-\")\n",
    "            )\n",
    "            product_name = source[1:-2]\n",
    "            plan_type = source[-4:-2]\n",
    "            doc.metadata[\"product_name\"] = \" \".join(product_name).title()\n",
    "            doc.metadata[\"plan_type\"] = \" \".join(plan_type)\n",
    "\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "        documents = text_splitter.split_documents(documents)\n",
    "\n",
    "        #vectordb = Chroma.from_documents(documents, embedding=OpenAIEmbeddings(), persist_directory=r\"C:\\Users\\dheer\\Downloads\\investment-advisor-gpt-main\\investment-advisor-gpt-main\\db\")\n",
    "        \n",
    "        vectordb = Chroma.from_documents(documents, embedding=embedding_func, persist_directory=r\"C:\\Users\\dheer\\Downloads\\investment-advisor-gpt-main\\investment-advisor-gpt-main\\db\")\n",
    "        vectordb.persist()\n",
    "\n",
    "    knowledge_base = RetrievalQA.from_chain_type(\n",
    "        llm=ChatOpenAI(),\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=vectordb.as_retriever(search_kwargs={\"k\": 7}),\n",
    "    )\n",
    "\n",
    "    return knowledge_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d364ae04-b20c-4e9d-853b-2419b5a0be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tools():\n",
    "    \"\"\"\n",
    "    Define tools usable by the Advisor Agent.\n",
    "    \"\"\"\n",
    "\n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "    knowledge_base = setup_knowledge_base(llm)\n",
    "    search = GoogleSerperAPIWrapper(type=\"news\")\n",
    "    tools = [\n",
    "        Tool(\n",
    "            name=\"WebSearch\",\n",
    "            func=search.run,\n",
    "            description=\"Access to google search. Always use this to obtain information about current events.\",\n",
    "        ),\n",
    "        Tool(\n",
    "            name=\"ProductSearch\",\n",
    "            func=knowledge_base.run,\n",
    "            description=\"Access to all our products. Always use this when asked about the products we offer\",\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    return tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e7d6d7-70e7-446f-ba26-5cf0fcbf9bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvestmentAdvisorGPT(Chain, BaseModel):\n",
    "    \"\"\"Controller model for the investment Agent.\"\"\"\n",
    "\n",
    "    conversation_history: Union[List[str], str]\n",
    "    conversation_stage: str = \"Introduction: Begin the cold call with a warm self-introduction. Include your name, company, and a credibility statement or reason for the prospect to stay engaged.\"\n",
    "    convo_stage_analyzer_chain: ConversationStageAnalyzerChain = Field(...)\n",
    "    conversation_response_chain: ConversationChain = Field(...)\n",
    "\n",
    "    agent_chain: Union[AgentExecutor, None] = Field(...)\n",
    "    use_tools: bool = False\n",
    "\n",
    "    conversation_stages_dict: Dict = {\n",
    "        \"1\": \"Introduction: Begin the cold call with a warm self-introduction. Include your name, company, and a credibility statement or reason for the prospect to stay engaged.\",\n",
    "        \"2\": \"Confirm: This is an important next stage right after [Introduction] to confirm if the prospect is the right person to discuss financial products/services. Check their age and authority for making financial decisions.\",\n",
    "        \"3\": \"Understanding the Prospect (Repeatable): Ask open-ended questions multiple times to uncover the prospect's financial needs and situation. Repeat this stage until you have gathered sufficient background information. Attempt to figure out what life stage they are currently in, and if they have any major life events happening soon that may impact their finances. Listen attentively. You are to infer the prospect's financial ability in terms of income, expenditure and financial aspiration.\",\n",
    "        \"4\": \"Huge Claim: Present an attention-grabbing claim related to the product/service. Connect it to the prospect's background in [Understanding the Prospect] discussed earlier.\",\n",
    "        \"5\": \"Product Introduction: Introduce some of the products you have that may best suit the prospect's background and needs (inferred in from [Understanding the Prospect]). If unsure of their needs, repeat [Understanding the Prospect] and ask more questions to generate a more informed understanding of the prospect.\",\n",
    "        \"6\": \"Value Proposition: Explain how our financial products/services benefit the prospect. Focus on their needs and emphasize unique selling points.\",\n",
    "        \"7\": \"Addressing Doubts: Handle skepticism about previous claims or product presentation. Provide evidence or testimonials.\",\n",
    "        \"8\": \"Closing: If the prospect is demonstrating keenness/enthuasisiam in your financial products/services, invite the prospect for a further discussion or meeting. Suggest potential dates and times.\",\n",
    "        \"9\": \"End conversation: The prospect has to leave to call, the prospect is not interested, or next steps where already determined by the sales agent.\",\n",
    "    }\n",
    "\n",
    "    advisor_name: str = \"Bobby Axelrod\"\n",
    "    advisor_role: str = \"private wealth advisor\"\n",
    "    nationality: str = \"Singaporean\"\n",
    "    formal_language: str = \"english\"\n",
    "    informal_language: str = \"singlish\"\n",
    "    company_name: str = \"UOB\"\n",
    "    company_business: str = \"provide unit trusts professionally managed by various fund managers, designed to meet customers' specific investment needs\"\n",
    "    conversation_purpose: str = \"find out if the prospect is interested in the latest investment products, specifically various mutual funds from Abrdn\"\n",
    "    conversation_type: str = \"cold call\"\n",
    "    source_of_contact: str = \"investment seminar\"\n",
    "    prospect_name: str = \"Jensen Low\"\n",
    "\n",
    "    @property\n",
    "    def input_keys(self) -> List[str]:\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def output_keys(self) -> List[str]:\n",
    "        return []\n",
    "\n",
    "    def clear_history(self):\n",
    "        \"\"\"Clears conversation history.\n",
    "\n",
    "        Act as a stand-in for `ConversationalBufferWindowMemory` to prevent exceeding token limits.\n",
    "        \"\"\"\n",
    "        # clear history to prevent existing tokens limit\n",
    "        # act as a stand-in for ConversationalBufferWindowMemory\n",
    "        if len(self.conversation_history) > 12:\n",
    "            # remove a pair of conversation together (human, ai)\n",
    "            for _ in range(2):\n",
    "                self.conversation_history.pop(0)\n",
    "\n",
    "    def retrieve_conversation_stage(self, key):\n",
    "        \"\"\"Retrieves the current conversation stage context.\n",
    "\n",
    "        Args:\n",
    "            key (str): Analyzed conversation stage id.\n",
    "\n",
    "        Returns:\n",
    "            str: Context of the current conversation stage.\n",
    "        \"\"\"\n",
    "        return self.conversation_stages_dict.get(key, \"1\")\n",
    "\n",
    "    def seed_agent(self):\n",
    "        \"\"\"Seed initial conversation stage.\"\"\"\n",
    "        # Step 1: seed the conversation\n",
    "        self.conversation_stage = self.retrieve_conversation_stage(\"1\")\n",
    "        if self.use_tools:\n",
    "            self.conversation_history = []\n",
    "        else:\n",
    "            self.conversation_history = \"\"\n",
    "\n",
    "    # TODO: fix to use memory from ether agent or cold call chain\n",
    "    def determine_conversation_stage(self):\n",
    "        \"\"\"\n",
    "        Determines the current stage of conversation based on the conversation history.\n",
    "\n",
    "        Returns:\n",
    "            str: Analyzed conversation stage id.\n",
    "        \"\"\"\n",
    "        conversation_stage_id = self.convo_stage_analyzer_chain.run(\n",
    "            conversation_history=\"\\n\".join(self.conversation_history),\n",
    "            conversation_stage=self.conversation_stage,\n",
    "        )\n",
    "\n",
    "        print(f\"Conversation Stage: {conversation_stage_id}\")\n",
    "        return conversation_stage_id\n",
    "\n",
    "    def human_step(self, human_input):\n",
    "        \"\"\"Process human input and adds to the conversation history.\"\"\"\n",
    "        # process human input\n",
    "        human_input = \"\\nUser: \" + human_input + \" <END_OF_TURN>\"\n",
    "        if self.use_tools:\n",
    "            self.conversation_history.append(human_input)\n",
    "        else:\n",
    "            human_input = human_input.removeprefix(\"\\nUser: \")\n",
    "            self.conversation_response_chain.memory.chat_memory.add_user_message(\n",
    "                human_input\n",
    "            )\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Run one step of the sales agent.\n",
    "\n",
    "        Returns:\n",
    "            str: Agent's response.\n",
    "        \"\"\"\n",
    "        return self._call(inputs={})\n",
    "\n",
    "    def _call(self, inputs: Dict[str, Any]) -> str:\n",
    "        \"\"\"Generates agent's response based on conversation stage and history.\"\"\"\n",
    "\n",
    "        self.conversation_stage = self.retrieve_conversation_stage(\n",
    "            self.determine_conversation_stage()\n",
    "        )\n",
    "        # Generate agent's utterance\n",
    "        if self.use_tools:\n",
    "            try:\n",
    "                # since we did not implement ConversationalBufferWindowMemory\n",
    "                # we mimick the setup by automatically conversation history, when hit messages\n",
    "                self.clear_history()\n",
    "                ai_message = self.agent_chain.run(\n",
    "                    input=\"\",\n",
    "                    conversation_stage=self.conversation_stage,\n",
    "                    conversation_history=\"\\n\".join(self.conversation_history),\n",
    "                    advisor_name=self.advisor_name,\n",
    "                    advisor_role=self.advisor_role,\n",
    "                    nationality=self.nationality,\n",
    "                    formal_language=self.formal_language,\n",
    "                    informal_language=self.informal_language,\n",
    "                    company_name=self.company_name,\n",
    "                    company_business=self.company_business,\n",
    "                    conversation_purpose=self.conversation_purpose,\n",
    "                    conversation_type=self.conversation_type,\n",
    "                    source_of_contact=self.source_of_contact,\n",
    "                    prospect_name=self.prospect_name,\n",
    "                )\n",
    "                self.conversation_stage = self.retrieve_conversation_stage(\n",
    "                    self.determine_conversation_stage()\n",
    "                )\n",
    "            # NOTE: hackish-way to deak with valid but unparseable output from llm: https://github.com/langchain-ai/langchain/issues/1358\n",
    "            except ValueError as e:\n",
    "                response = str(e)\n",
    "                if not response.startswith(\"Could not parse LLM output: `\"):\n",
    "                    raise e\n",
    "                ai_message = response.removeprefix(\n",
    "                    \"Could not parse LLM output: `\"\n",
    "                ).removesuffix(\"`\")\n",
    "                # TODO: this is a temp measure to not display bot message to user.\n",
    "                # this occurs when bot cannot follow instruction when using tools.\n",
    "                # there are other occurence as well\n",
    "                if \"Do I need to use a tool?\" in ai_message:\n",
    "                    ai_message = (\n",
    "                        \"Sorry, I didn't quite catch that. Do you mind repeating?\"\n",
    "                    )\n",
    "        else:\n",
    "            ai_message = self.conversation_response_chain.run(\n",
    "                input=\"\",\n",
    "                conversation_stage=self.conversation_stage,\n",
    "                conversation_history=self.conversation_history,\n",
    "                advisor_name=self.advisor_name,\n",
    "                advisor_role=self.advisor_role,\n",
    "                nationality=self.nationality,\n",
    "                formal_language=self.formal_language,\n",
    "                informal_language=self.informal_language,\n",
    "                company_name=self.company_name,\n",
    "                company_business=self.company_business,\n",
    "                conversation_purpose=self.conversation_purpose,\n",
    "                conversation_type=self.conversation_type,\n",
    "                source_of_contact=self.source_of_contact,\n",
    "                prospect_name=self.prospect_name,\n",
    "            )\n",
    "            # self.conversation_history = self.conversation_response_chain.memory.buffer\n",
    "            self.conversation_history = (\n",
    "                self.conversation_response_chain.memory.load_memory_variables({})[\n",
    "                    \"conversation_history\"\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        # Add agent's response to conversation history\n",
    "        if \"<END_OF_TURN>\" in ai_message:\n",
    "            display_message = ai_message.rstrip(\"<END_OF_TURN>\")\n",
    "        elif \"<END_OF_CALL>\" in ai_message:\n",
    "            display_message = ai_message.rstrip(\"<END_OF_CALL>\")\n",
    "        else:\n",
    "            display_message = ai_message\n",
    "        # stdout message\n",
    "        print(\n",
    "            colored(\n",
    "                f\"{self.advisor_name}: \" + display_message,\n",
    "                \"magenta\",\n",
    "            )\n",
    "        )\n",
    "        if (\"<END_OF_TURN>\" not in ai_message) and (\"<END_OF_CALL>\" not in ai_message):\n",
    "            ai_message += \" <END_OF_TURN>\"\n",
    "        agent_name = self.advisor_name\n",
    "        ai_message = agent_name + \": \" + ai_message\n",
    "        if self.use_tools:\n",
    "            self.conversation_history.append(ai_message)\n",
    "        else:\n",
    "            self.conversation_response_chain.memory.chat_memory.add_ai_message(\n",
    "                ai_message.removeprefix(agent_name + \": \")\n",
    "            )\n",
    "\n",
    "        return ai_message\n",
    "\n",
    "    @classmethod\n",
    "    def from_llm(\n",
    "        cls, llm: BaseLLM, verbose: bool = False, **kwargs\n",
    "    ) -> \"InvestmentAdvisorGPT\":\n",
    "        \"\"\"Initialize the InvestmentAdvisorGPT Controller.\"\"\"\n",
    "        # ref: https://stackoverflow.com/questions/76941870/valueerror-one-input-key-expected-got-text-one-text-two-in-langchain-wit\n",
    "        memory = ConversationBufferWindowMemory(\n",
    "            k=12,\n",
    "            memory_key=\"conversation_history\",\n",
    "            ai_prefix=kwargs.get(\"advisor_name\"),\n",
    "            human_prefix=kwargs.get(\"prospect_name\"),\n",
    "            input_key=\"input\",\n",
    "        )\n",
    "        readonlymemory = ReadOnlySharedMemory(memory=memory)\n",
    "        conversation_response_chain = ConversationChain.from_llm(\n",
    "            llm, memory=memory, verbose=verbose\n",
    "        )\n",
    "\n",
    "        if \"use_tools\" in kwargs and kwargs[\"use_tools\"] is False:\n",
    "            agent_chain = None\n",
    "            # ref: https://python.langchain.com/docs/modules/agents/how_to/sharedmemory_for_tools\n",
    "            # to prevent memory from being modified by other chains\n",
    "            convo_stage_analyzer_chain = ConversationStageAnalyzerChain.from_llm(\n",
    "                llm, verbose=verbose, memory=readonlymemory\n",
    "            )\n",
    "        else:\n",
    "            convo_stage_analyzer_chain = ConversationStageAnalyzerChain.from_llm(\n",
    "                llm, verbose=verbose\n",
    "            )\n",
    "            tools = get_tools()\n",
    "            prompt = CustomPromptTemplate(\n",
    "                template=ADVISOR_TOOLS_PROMPT,\n",
    "                tools_getter=lambda x: tools,\n",
    "                # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "                # This includes the `intermediate_steps` variable because that is needed\n",
    "                input_variables=[\n",
    "                    \"input\",\n",
    "                    \"intermediate_steps\",\n",
    "                    \"advisor_name\",\n",
    "                    \"advisor_role\",\n",
    "                    \"nationality\",\n",
    "                    \"formal_language\",\n",
    "                    \"informal_language\",\n",
    "                    \"company_name\",\n",
    "                    \"company_business\",\n",
    "                    \"conversation_purpose\",\n",
    "                    \"conversation_type\",\n",
    "                    \"source_of_contact\",\n",
    "                    \"prospect_name\",\n",
    "                    \"conversation_stage\",\n",
    "                    \"conversation_history\",\n",
    "                ],\n",
    "            )\n",
    "            llm_chain = LLMChain(llm=llm, prompt=prompt, verbose=verbose)\n",
    "\n",
    "            # It makes assumptions about output from LLM which can break and throw an error\n",
    "            output_parser = CustomOutputParser(ai_prefix=kwargs[\"advisor_name\"])\n",
    "            tool_names = [tool.name for tool in tools]\n",
    "            agent_with_tools = LLMSingleActionAgent(\n",
    "                llm_chain=llm_chain,\n",
    "                output_parser=output_parser,\n",
    "                stop=[\"\\nObservation:\"],\n",
    "                allowed_tools=tool_names,\n",
    "                verbose=verbose,\n",
    "            )\n",
    "\n",
    "            agent_chain = AgentExecutor.from_agent_and_tools(\n",
    "                agent=agent_with_tools, tools=tools, verbose=verbose\n",
    "            )\n",
    "\n",
    "        return cls(\n",
    "            convo_stage_analyzer_chain=convo_stage_analyzer_chain,\n",
    "            conversation_response_chain=conversation_response_chain,\n",
    "            agent_chain=agent_chain,\n",
    "            verbose=verbose,\n",
    "            **kwargs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cfd3f6-f543-48ab-b2f3-f7d77c936aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9648b830-016e-4af6-977e-ed598efa4730",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcbbfdd-5867-41da-b510-f1e729cd1820",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9)\n",
    "with open(r\"C:\\Users\\dheer\\Downloads\\investment-advisor-gpt-main\\investment-advisor-gpt-main\\src\\model\\configs\\examples\\agent_singaporean_male.json\") as f:\n",
    "    configs = json.load(f)\n",
    "advisor_agent = InvestmentAdvisorGPT.from_llm(llm, **configs)  # type: ignore\n",
    "advisor_agent.seed_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e916a57b-374a-402c-971e-c7e5b59a4778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b0b59c-eada-4055-87ca-668a262d6be7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_app1",
   "language": "python",
   "name": "rag_app1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
